\inputencoding{latin1}
\HeaderA{BEM}{BACON-EEM Algorithm for multivariate outlier detection in incomplete multivariate survey data}{BEM}
\keyword{robust}{BEM}
\keyword{survey}{BEM}
\keyword{multivariate}{BEM}
%
\begin{Description}\relax
BEM starts from a set of uncontaminated data with possible missing values, applies a version of the EM-algorithm
to estimate the center and scatter of the good data, then adds (or deletes) observations to the good data which have	 
a Mahalanobis distance below a threshold. This process iterates until the good data remain stable. Observations not 
among the good data are outliers.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
BEM(data, weights, v = 2, c0 = 3, alpha = 0.01, md.type = "m", em.steps.start = 10, em.steps.loop = 5, better.estimation = F, monitor = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a matrix or data frame. As usual, rows are observations and columns are variables.
\item[\code{weights}] a non-negative and non-zero vector of weights for each observation. 
Its length must equal the number of rows of the data. Default is \code{rep(1,nrow(data))}.
\item[\code{v}] an integer indicating the distance for the definition of the starting good subset: v=1 uses the Mahalanobis distance based 
on the weighted mean and covariance, v=2 uses the Euclidean distance from the componentwise median
\item[\code{c0}] the size of initial subset is c0*ncol(data).
\item[\code{alpha}] a probability indicating the level \code{(1-alpha)} of the cutoff quantile for good observations
\item[\code{md.type}] Type of Mahalanobis distance: "m" marginal, "c" conditional
\item[\code{em.steps.start}] Number of iterations of EM-algorithm for starting good subset
\item[\code{em.steps.loop}] Number of iterations of EM-algorithm for good subset
\item[\code{better.estimation}] If \code{better.estimation=TRUE} then the EM-algorithm 
for the final good subset iterates \code{em.steps.start} more.
\item[\code{monitor}] If \code{TRUE} verbose output.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The BACON algorithm with \code{v=1} is not robust but affine equivariant. The threshold for Mahalanobis distances is 
a chisquare quantile at \code{(1-alpha)}. For relatively small data sets it may be better to choose \code{alpha/n} instead.

The internal function \code{.EM.normal} is usually called from \code{BEM}. \code{.EM.normal} is implementing the EM-algorithm in such a way that part of the calculations can be saved to be reused in the BEM algorithm. \code{.EM.normal} does not contain the computation of the observed sufficient statistics, they will be computed in the main program of \code{BEM} and passed as parameters as well as the statistics on the missingness patterns.
\end{Details}
%
\begin{Value}
The output is stored in two global variables \code{BEM.r} and \code{BEM.i}. \code{BEM.r} contains the following components: 
\begin{ldescription}
\item[\code{sample.size }] number of observations
\item[\code{discarded.observations}] Number of discarded observations
\item[\code{number.of.variables }] Number of variables
\item[\code{significance.level}] \code{alpha}
\item[\code{initial.basic.subset.size}] Size of initial good subset
\item[\code{final.basic.subset.size}] Size of final good subset
\item[\code{number.of.iterations}] Number of iterations of the BACON step
\item[\code{computation.time}] Elapsed computation time
\item[\code{center}] Final estimate of the center
\item[\code{scatter}] Final estimate of the covariance matrix
\item[\code{cutpoint}] The threshold MD-value for the cut-off of outliers

\end{ldescription}
\code{BEM.i} contains the following components:
\begin{ldescription}
\item[\code{outind}] Outlier indicator
\item[\code{dist}] Final Mahalanobis distances
\end{ldescription}
\end{Value}
%
\begin{Note}\relax
 BEM uses an adapted version of the EM-algorithm in funkction \code{EM-normal.}
\end{Note}
%
\begin{Author}\relax
Beat Hulliger
\end{Author}
%
\begin{References}\relax
B\bsl{}'eguin, C. and Hulliger, B. (2008) The BACON-EEM Algorithm for Multivariate Outlier Detection 
in Incomplete Survey Data, \emph{Survey Methodology}, Vol. 34, No. 1, pp. 91-103.

Billor, N., Hadi, A.S. and Vellemann, P.F. (2000). BACON: Blocked
Adaptative Computationally-efficient Outlier Nominators. \emph{Computational Statistics and Data Analysis}, 
34(3), 279-298.

Schafer J.L. (2000),
\emph{Analysis of Incomplete Multivariate Data}, Monographs on Statistics and Applied Probability 72,
Chapman \& Hall.

\end{References}
%
\begin{Examples}
\begin{ExampleCode}
# Bushfire data set with 20% MCAR
data(bushfirem,bushfire.weights)
BEM(bushfirem,bushfire.weights,alpha=(1-0.01/nrow(bushfirem)))
\end{ExampleCode}
\end{Examples}
